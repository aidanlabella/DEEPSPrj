% 2nd Milestone
\documentclass[12pt]{article}

\usepackage[a4paper,margin=0.85in,footskip=0.25in]{geometry}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{palatino}
\usepackage{setspace}
\usepackage{pgfplots}
\usepackage{graphics}
\usepackage{dirtytalk}
\usepackage{dramatist}


\pgfplotsset{compat=1.16}
\bibliographystyle{plain} % Change this to your desired style
% \addbibresource{sources.bib}


\begin{document}
\noindent
Aidan LaBella \\
DATA/EEPS 1720 \\
Project Milestone 2\\
4/2/2024 \\

\section{Introduction}
\indent
The main question my project attempts to answer is \say{can we impute air quality data when sensor data is unreliable and/or not present}? This project, at a high level, is to train a model that is effective at predicting air pollution given certain parameters. I also propose using a toolkit for neural architecture search while training the model. The applications of a model that can predict air quality vary from being able to estimate the pollutants in the air based on other parameters, to being able to accurately forecast when the pollution will reach its high/low levels, much like a weather forecast. 

Recurrent Neural Networks, or RNNs are an effective way to regress over a dataset. Since RNNs are able to output a set of parameters for a variable number of time-steps, this makes them ideally suited for time series forecasting. Air quality data takes the form of hourly readings from sensors that measure different contents of elements in the air. As such, RNNs can be said to be well-suited for this type of time series forecasting. However, one of the drawbacks that RNNs bring is a computational overhead due to their need to be “unrolled” through time. Because of this, creating smaller recurrent neural networks has been a priority in the DL field but finding the right architecture has been a challenge. Using the Evolutionary eXploration of Augmenting Memory Models (EXAMM)\cite{ororbia_investigating_2019}, we can “evolve'' recurrent neural networks to (hopefully) be the “smallest” yet best performing model for a given task. Not only does this reduce the complexity of the model, it can reduce the computational cost which in turn makes the model more environmentally friendly. Smaller We will show that our evolved networks can achieve the same levels of performance as a traditional RNN in PyTorch or Tensorflow.

\section{Related Work}
\indent
Previous applications of the EXAMM\cite{ororbia_investigating_2019} toolkit with neural architecture search (NAS) include making predictions for coal power plants\cite{kaufmann_evolving_2019}. Pure LSTM-RNNs have also been explored and show promising results in time series forecasting \cite{belavadi2020air}.\\
\\
\begin{footnotesize}
    \textbf{Note:} This will be expanded for the final submission.
\end{footnotesize}

\section{Dataset}
It is important to first note that this work can be classified as a multivariate time series classification forecasting task. The data that will be used to train the models will be multivariate in form, with one or more columns potentially missing or corrupted to simulate unreliable data.
To train a well-performing recurrent neural network, we must first find a well-curated dataset that has enough sensor readings to learn from. The UC Irvine Air Quality dataset \cite{misc_air_quality_360} uses 9358 instances of hourly averaged responses from an array of 5 sensors within an Italian city from March 2004 to February 2005, approximately 1 year in time.

\section{Exploratory Analysis}
For a \say{proof of concept}, the entire dataset was used to \say{evolve} network(s) and evaluate their performance. In NAS, evolution refers to the process of augmenting the model's architecture through random mutations, followed by gradient descent for adequate evaluation. In the experiments conducted, we attempt to impute the ground truth readings based on date, time, temperature and other sensor readings. We evolve the networks for 2000 genomes (series of mutations) with 5 epochs of gradient descent for evaluation. The preliminary MSE values of well-performing genomes (models) for univariate ouputs has been found to be in the ballpark of $[.02,.04]$, an acceptable range for any deep learning model. For multivariate outputs, the loss was higher ($\geq 0.2$). Thus, I am confident that an evolved RNN will be well-suited to make predictions for this task. 

\begin{figure}
    \includegraphics[width=\linewidth]{resources/init_genome.png}
    \caption{The architecture of the inital evolved RNN for univariate predictions.}
\end{figure}

\begin{figure}
    \includegraphics[width=\linewidth]{resources/init_genome_mv0.png}
    \caption{The architecture of the inital evolved RNN for multivariate predictions.}
\end{figure}

\section{Methods}
For the coming weeks, I will answer the following research questions (ranked by priority):\\
\textbf{RQ1:} What input columns can accurately estimate the levels of pollutants such as Benzene, $NO_2$ and $NO_x$? These values are denoted in the dataset as GT (ground truth).\\
\textbf{RQ2:} Can multiple prediction columns exist in the output layer with minimal performance impact? I.e. can we predict multiple columns at once? \\
\begin{footnotesize}
    Note: \textbf{RQ1} and \textbf{RQ2} may require additional data sources. For now, the UCI dataset is sufficient.\\
\end{footnotesize}
\textbf{RQ3:} How do our imputed values compare with actual sensor readings?\\
\textbf{RQ4:} What is the inference time of the best performing model? How does it compare to a standard Jordan, Elman and standard RNNs? \\
The experiments that will be conducted will be as follows:
\begin{enumerate}
    \item
        Evolve RNNs to predcit GT values. Vary the input columns. Determine which set of input parameters is \say{the best} based on MSE/MAE. Perform post-training if necessary (Answers \textbf{RQ1})
    \item
        Create distributions of the predicted values and plot predictions for final paper. (Answers \textbf{RQ3}, \textbf{RQ1})
    \item
        Feed the same dataset into a torch RNN. Compare inference time and performance to that of EXAMM. (Answers \textbf{RQ4})
    \item
        Repeat the above experiements for multivariate and univariate output layers. (Answers \textbf{RQ2})
\end{enumerate}


\section{Evaluation}
To evaluate both \textbf{RQ1} and \textbf{RQ2}, both mean average error (MAE) and mean squared error (MSE) will be used. Plots and distributions will also be created to showcase the models performance for \textit{each} timestep in the series.\\

\bibliography{sources} % Replace with your BibTeX filename
\end{document}
